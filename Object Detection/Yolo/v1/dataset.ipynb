{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29393b49",
   "metadata": {},
   "source": [
    "### How Yolo Dataset preprocess the Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0cb0d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e9d8fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.        ,  0.34419263,  0.611     ,  0.41643059,  0.262     ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbs = np.array([[11, 0.34419263456090654, 0.611, 0.4164305949008499, 0.262]\n",
    ",[14, 0.509915014164306, 0.51, 0.9745042492917847, 0.972]])\n",
    "bb = bbs[0]\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c42f1478",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "s: cell size\n",
    "b: number of boxes\n",
    "c: number of classes (20 for voc)\n",
    "\"\"\"\n",
    "s=3\n",
    "b=1\n",
    "c=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb24e90",
   "metadata": {},
   "source": [
    "### Convert to be with respect to cells instead of the whole image  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea216d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 25)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_matrix = np.zeros((s, s, c+b*5))\n",
    "label_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1da846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a single box, data in format (label, x-midpoint, y-midpoint, width, height)\n",
    "class_label, x, y, width, height = bb\n",
    "class_labe = int(class_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5472a54",
   "metadata": {},
   "source": [
    "####  Convert midpoint to be with respect to the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef1a052d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 1, j: 1\n",
      "x: 0.34419263456090654, y: 0.611\n",
      "x_cell: 0.03257790368271962, y_cell: 0.833\n"
     ]
    }
   ],
   "source": [
    "# get i,j: represent cell row and column\n",
    "i,j = int(s*y), int(s*x)\n",
    "print(f\"i: {i}, j: {j}\")\n",
    "x_cell, y_cell = s*x-j, s*y-i\n",
    "print(f\"x: {x}, y: {y}\")\n",
    "print(f\"x_cell: {x_cell}, y_cell: {y_cell}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bc0b35",
   "metadata": {},
   "source": [
    "#### Convert the width and height of the box to be with respect to the cell\n",
    "can be greater than 1 if box dimension is greater than the cell dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd5a7523",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width: 0.4164305949008499, height: 0.262\n",
      "width_cell: 1.2492917847025495, height_cell: 0.786\n"
     ]
    }
   ],
   "source": [
    "width_cell, height_cell = width * s, height * s\n",
    "print(f\"width: {width}, height: {height}\")\n",
    "print(f\"width_cell: {width_cell}, height_cell: {height_cell}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
